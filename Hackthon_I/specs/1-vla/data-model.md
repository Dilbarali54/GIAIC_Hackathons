# Data Model: Vision-Language-Action (VLA) Module

**Feature**: 1-vla (Vision-Language-Action Module)
**Date**: 2025-12-17
**Status**: Complete

## Overview

This document defines the key data structures and entities for the Vision-Language-Action (VLA) module, focusing on the educational content and technical implementation for voice-to-action, cognitive planning, and autonomous humanoid execution.

## Core Entities

### 1. VoiceCommand

**Description**: Represents a natural language command spoken by the user

**Fields**:
- `id` (string): Unique identifier for the command
- `audio_data` (bytes): Raw audio data or file path
- `transcribed_text` (string): Text from speech-to-text conversion
- `timestamp` (datetime): When the command was received
- `language` (string): Language of the original speech
- `confidence` (float): Confidence score from speech recognition (0.0-1.0)
- `user_context` (object): Additional context about the user's environment

**Validation Rules**:
- `transcribed_text` must not be empty
- `confidence` must be between 0.0 and 1.0
- `timestamp` must be current or recent (not in future)

### 2. CognitivePlan

**Description**: Structured plan generated by LLM to accomplish the requested task

**Fields**:
- `id` (string): Unique identifier for the plan
- `original_command` (string): The original transcribed text
- `intent` (string): High-level intent extracted from the command
- `action_sequence` (array): Ordered list of actions to execute
- `context` (object): Environmental context relevant to execution
- `confidence` (float): LLM's confidence in the plan (0.0-1.0)
- `timestamp` (datetime): When the plan was generated
- `status` (string): Current status (pending, executing, completed, failed)

**Validation Rules**:
- `action_sequence` must contain at least one action
- `intent` must be non-empty
- `confidence` must be between 0.0 and 1.0

### 3. RobotAction

**Description**: A specific action to be executed by the robot

**Fields**:
- `id` (string): Unique identifier for the action
- `type` (string): Type of action (move, pick, place, speak, etc.)
- `parameters` (object): Specific parameters for the action
- `priority` (integer): Execution priority (1-10, 1 being highest)
- `timeout` (integer): Maximum time to execute in seconds
- `dependencies` (array): List of action IDs that must complete first
- `success_conditions` (array): Conditions that define successful completion

**Validation Rules**:
- `type` must be a valid action type
- `priority` must be between 1 and 10
- `timeout` must be positive

### 4. ROS2Command

**Description**: ROS 2 specific command derived from a RobotAction

**Fields**:
- `id` (string): Unique identifier
- `action_type` (string): ROS 2 action type (e.g., "move_base_msgs/MoveBaseAction")
- `goal` (object): ROS 2 goal message structure
- `action_server` (string): Target action server name
- `feedback_callback` (string): Callback function name for feedback
- `result_callback` (string): Callback function name for results
- `timeout` (integer): Action timeout in seconds

**Validation Rules**:
- `action_type` must match valid ROS 2 action types
- `timeout` must be positive

### 5. ExecutionResult

**Description**: Result of executing a robot action

**Fields**:
- `id` (string): Unique identifier
- `action_id` (string): Reference to the executed action
- `status` (string): Execution status (success, failure, timeout, cancelled)
- `result_data` (object): Data returned from the action execution
- `error_message` (string): Error description if action failed
- `execution_time` (float): Time taken to execute in seconds
- `timestamp` (datetime): When execution completed

**Validation Rules**:
- `status` must be one of the defined values
- If `status` is "failure", `error_message` must be provided

### 6. LearningModule

**Description**: Educational content module for the VLA system

**Fields**:
- `id` (string): Unique identifier
- `title` (string): Title of the module
- `chapter_number` (integer): Chapter sequence (1-3 for VLA)
- `content` (string): Markdown content of the chapter
- `code_examples` (array): List of code examples in the chapter
- `exercises` (array): Practice exercises for students
- `objectives` (array): Learning objectives
- `prerequisites` (array): Required knowledge or setup steps
- `duration` (integer): Estimated completion time in minutes

**Validation Rules**:
- `chapter_number` must be between 1 and 3
- `content` must be non-empty
- `objectives` must contain at least one objective

### 7. SystemConfiguration

**Description**: Configuration parameters for the VLA system

**Fields**:
- `id` (string): Unique identifier
- `openai_api_key` (string): OpenAI API key (stored securely)
- `ros_domain_id` (integer): ROS 2 domain ID
- `robot_model` (string): Type of robot being controlled
- `simulation_mode` (boolean): Whether to use simulation or real hardware
- `audio_device_index` (integer): Audio input device index
- `whisper_model` (string): Whisper model to use (default: "whisper-1")
- `llm_model` (string): LLM model for cognitive planning
- `safety_limits` (object): Safety parameters for robot movement

**Validation Rules**:
- `ros_domain_id` must be non-negative
- `audio_device_index` must be valid device index
- `simulation_mode` must be boolean

## Relationships

### VoiceCommand → CognitivePlan
- One VoiceCommand generates one CognitivePlan
- Relationship: 1:1 (each command creates one plan)

### CognitivePlan → RobotAction
- One CognitivePlan contains multiple RobotActions
- Relationship: 1:many (one plan has multiple sequential actions)

### RobotAction → ROS2Command
- One RobotAction maps to one or more ROS2Commands
- Relationship: 1:many (complex actions may require multiple ROS commands)

### RobotAction → ExecutionResult
- One RobotAction produces one ExecutionResult
- Relationship: 1:1 (each action execution creates one result)

### LearningModule → SystemConfiguration
- LearningModule may reference specific SystemConfiguration
- Relationship: many:1 (multiple modules may use same configuration)

## State Transitions

### CognitivePlan States
```
pending → executing → [completed | failed]
```

### RobotAction States
```
pending → executing → [completed | failed | timeout | cancelled]
```

### VoiceCommand States
```
received → processing → [transcribed | failed]
```

## Data Validation

### Input Validation
- All text inputs should be sanitized to prevent injection attacks
- Audio files must be in supported formats (WAV, MP3, etc.)
- Command lengths should be reasonable (less than 1000 characters)

### Business Logic Validation
- Action dependencies must form a valid directed acyclic graph (DAG)
- No circular dependencies between actions
- Safety limits must not be exceeded
- Robot state must be consistent with action requirements

## Performance Considerations

### Data Storage
- VoiceCommand and ExecutionResult data may accumulate rapidly
- Consider time-based retention policies for logs
- Cache frequently accessed CognitivePlan templates

### Processing Efficiency
- Optimize LLM calls to minimize API costs
- Cache results for common command patterns
- Implement streaming for real-time audio processing